8a.
1.How many cpus c are detected by running your test program? 8 cores on a M1 chip
2.What is the maximal speedup s obtained for this program? 3.40x speedup on a 200 sized matrix run 16 times
3.What is the pool size p at which your maximal speedup is obtained? Pool size of 8.
4.Explain the differences between c, s, and p in a paragraph of 4 or 5 sentences.
In my M1 mac with no Simultaneous Multithreading, it is expected that the maximal speedup is obtained when the pool size(8) matches the physical core count(8). This fully utilises every core for the calculation of matrix multiplication.
The speedup is not 8 times even though we are using 8 cores as we are bottlenecked by the sequential part of the execution, such as creating the 8 processes, synchronisation and gathering all the data from the 8 processes back into 1. By Amdahl's law, this serial portion bottlenecks the execution and prevents us from seeing the full 8x speedup. In addition specifically on my M1 Macbook Pro, I have 4 fast performance cores and 4 slower efficiency cores. When running sequentially, all the multiplication takes place on 1 performance core, but the 8 process setup has 4 processes running on the efficiency cores. As the program is designed so the it only returns when we finish execution on all cores, we are bottlenecked by the efficieny cores and are hence essentially comparing the sequential execution on a performance core versus parallel execution on an efficiency core, resulting in <8x speedup.

8b.
1.What is the biggest n such that a single CPU can carry out 25 matrix multiplications of size n x n within one second? n=2000 on a M1 Chip Macbook Pro
2.Varying the matrix size, what is the biggest speedup p that you can obtain using GPUs, compared to the performance of a single CPU? ~1.56x
3.What is the matrix size s for which the speedup p was achieved? n=3000
4.Investigate the GPU configuration of your PC. How does your GPU configuration relate to the numbers s and p? Explain in three or four sentences how the GPU configuration can explain the experiments?
My GPU is the M1's GPU, with 8 cores, each with 16 execution units(EU) with 8 Arithmetic Logic units(ALUs) for a total of 1024 ALUs. My CPU, assuming it is not superscalar and can only handle 1 instruction at once, has a total of 8 ALUs for execution for its 8 cores. Hence, we see a significant speedup when using the GPU as compared to the CPU. To account for the speedup not being 1024 / 8, we have to consider that the GPU is a SIMT architecture where each execution 128 execution units executing 1 instruction on 8 threads, so we cant fully utilise every thread if there are different code paths. Beyond that, we see that the GPU runs at a lower clock speed than the CPU, ~1.3Ghz vs3.2Ghz, as the GPU is optimised for throughput and not latency like the CPU. Hence, an ALU takes longer to finish the same calcuation in the GPU than the CPU, resulting in the less than perfect speedup.

8c.
From my tests all three precisions will time out on Google Collab and even on my local device with a RTX4060 before we can find the maximal speedup. Since a decently powerful GPU has magnitudes greater FLOPS than even the best CPU, we end up with the maximal seedup continuously increasing as the matrix size increases and I cant reasonably find the limit as the CPU execution time is just too long to be calculated.

In general we see that the smaller the precision size the faster the execution will be for the GPU matrix multiplication. This is because there is less data being moved around and processed with smaller precisions, reducing memory transfer times and processing times. In addition, most CUDA architectures support running 16 bit(half) cacluations in paralle on their single precision(32 bit) and double precision(64 bit) ALUs, this means that the 16 bit precision multiplication can run the fastest. Generally, the FLOPS for single precision is higher than that of double precision as most GPUs are optimised for single precision calculations and have more of that respective ALU type. So, the single precision calcluations are executed faster than the double precision calculations. 
